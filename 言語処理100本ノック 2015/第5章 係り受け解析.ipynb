{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "夏目漱石の小説『吾輩は猫である』の文章（neko.txt）をCaboChaを使って係り受け解析し，その結果をneko.txt.cabochaというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import requests\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "r = requests.get(\"http://www.cl.ecei.tohoku.ac.jp/nlp100/data/neko.txt\", stream=True)\n",
    "\n",
    "with open(\"neko.txt\", 'wb') as f:\n",
    "    r.raw.decode_content = True\n",
    "    shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "! cabocha -f1 neko.txt > neko.txt.cabocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，CaboChaの解析結果（neko.txt.cabocha）を読み込み，各文をMorphオブジェクトのリストとして表現し，3文目の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Morph: {\"surface\": \"名前\", \"base\": \"一般\" ,\"pos\": \"名前\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"は\", \"base\": \"係助詞\" ,\"pos\": \"は\", \"pos1\": \"助詞\"}, Morph: {\"surface\": \"まだ\", \"base\": \"助詞類接続\" ,\"pos\": \"まだ\", \"pos1\": \"副詞\"}, Morph: {\"surface\": \"無い\", \"base\": \"自立\" ,\"pos\": \"無い\", \"pos1\": \"形容詞\"}, Morph: {\"surface\": \"。\", \"base\": \"句点\" ,\"pos\": \"。\", \"pos1\": \"記号\"}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class Morph:    \n",
    "    def __init__(self, surface, pos, pos1, base):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"Morph: {\\\"surface\\\": \\\"%s\\\", \\\"base\\\": \\\"%s\\\" ,\\\"pos\\\": \\\"%s\\\", \\\"pos1\\\": \\\"%s\\\"}\" %\n",
    "                (self.surface, self.base, self.pos, self.pos1))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "def make_morph(word):\n",
    "    splitted = re.split('[\\t,]', word)\n",
    "    return Morph(splitted[0], splitted[7], splitted[1], splitted[2])\n",
    "    \n",
    "def make_morph_list(file_path):\n",
    "    with open(file_path, \"rt\") as neko:\n",
    "        return [[make_morph(word) for word in line.split('\\n')\n",
    "                 if len(word) >= 4 and not re.match(r'^\\*.*', word)]\n",
    "            for line in re.split(r'EOS\\n', neko.read())\n",
    "                if len(line) is not 0]\n",
    "\n",
    "print(make_morph_list(\"neko.txt.cabocha\")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストのCaboChaの解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，8文目の文節の文字列と係り先を表示せよ．第5章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   Chunk: {\"morphs\": [Morph: {\"surface\": \"しかも\", \"base\": \"*\" ,\"pos\": \"しかも\", \"pos1\": \"接続詞\"}], \"dst\": 8, \"srcs\" []},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"あと\", \"base\": \"一般\" ,\"pos\": \"あと\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"で\", \"base\": \"格助詞\" ,\"pos\": \"で\", \"pos1\": \"助詞\"}], \"dst\": 2, \"srcs\" []},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"聞く\", \"base\": \"自立\" ,\"pos\": \"聞く\", \"pos1\": \"動詞\"}, Morph: {\"surface\": \"と\", \"base\": \"接続助詞\" ,\"pos\": \"と\", \"pos1\": \"助詞\"}], \"dst\": 8, \"srcs\" [1]},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"それ\", \"base\": \"代名詞\" ,\"pos\": \"それ\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"は\", \"base\": \"係助詞\" ,\"pos\": \"は\", \"pos1\": \"助詞\"}], \"dst\": 8, \"srcs\" []},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"書生\", \"base\": \"一般\" ,\"pos\": \"書生\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"という\", \"base\": \"格助詞\" ,\"pos\": \"という\", \"pos1\": \"助詞\"}], \"dst\": 5, \"srcs\" []},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"人間\", \"base\": \"一般\" ,\"pos\": \"人間\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"中\", \"base\": \"接尾\" ,\"pos\": \"中\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"で\", \"base\": \"格助詞\" ,\"pos\": \"で\", \"pos1\": \"助詞\"}], \"dst\": 8, \"srcs\" [4]},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"一番\", \"base\": \"副詞可能\" ,\"pos\": \"一番\", \"pos1\": \"名詞\"}], \"dst\": 7, \"srcs\" []},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"獰悪\", \"base\": \"形容動詞語幹\" ,\"pos\": \"獰悪\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"な\", \"base\": \"*\" ,\"pos\": \"だ\", \"pos1\": \"助動詞\"}], \"dst\": 8, \"srcs\" [6]},\n",
      "    Chunk: {\"morphs\": [Morph: {\"surface\": \"種族\", \"base\": \"一般\" ,\"pos\": \"種族\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"で\", \"base\": \"*\" ,\"pos\": \"だ\", \"pos1\": \"助動詞\"}, Morph: {\"surface\": \"あっ\", \"base\": \"*\" ,\"pos\": \"ある\", \"pos1\": \"助動詞\"}, Morph: {\"surface\": \"た\", \"base\": \"*\" ,\"pos\": \"た\", \"pos1\": \"助動詞\"}, Morph: {\"surface\": \"そう\", \"base\": \"特殊\" ,\"pos\": \"そう\", \"pos1\": \"名詞\"}, Morph: {\"surface\": \"だ\", \"base\": \"*\" ,\"pos\": \"だ\", \"pos1\": \"助動詞\"}, Morph: {\"surface\": \"。\", \"base\": \"句点\" ,\"pos\": \"。\", \"pos1\": \"記号\"}], \"dst\": -1, \"srcs\" [0, 2, 3, 5, 7]}]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, morphs, dst, srcs):\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = srcs\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\"Chunk: {\\\"morphs\\\": %s, \\\"dst\\\": %s, \\\"srcs\\\" %s}\" %\n",
    "                (self.morphs, self.dst, self.srcs))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "def list_sentences(string):\n",
    "    return re.split(r'EOS\\n', string)\n",
    "\n",
    "def list_chunks(sentence):\n",
    "    pattern = re.compile(r'^(\\*.*)$((\\n([^*].*))+)', re.MULTILINE)\n",
    "    chunk_list = []\n",
    "    dst_src_dict = defaultdict(list)\n",
    "    \n",
    "    def filter_morphs(morphs):\n",
    "        return [m for m in morphs.split('\\n') if not len(m) == 0 and m != 'EOS']\n",
    "    \n",
    "    def parse_phrase(phrase):\n",
    "        return re.match(r'^\\*\\s\\d*\\s(-?\\d*)D', phrase).group(1)\n",
    "    \n",
    "    def make_morph(word):\n",
    "        splitted = re.split('[\\t,]', word)\n",
    "        return Morph(splitted[0], splitted[7], splitted[1], splitted[2])\n",
    "    \n",
    "    def make_chunk(phrase, morph_list):\n",
    "        idnt, dst = re.match(r'^\\*\\s(\\d*)\\s(-?\\d*)D', phrase).groups()\n",
    "        srcs = dst_src_dict[idnt]\n",
    "        morphs = [make_morph(x) for x in morph_list]\n",
    "        return (Chunk(morphs, dst, srcs), idnt, dst)\n",
    "\n",
    "    for phrase, morphs, _, _ in [phrase.groups() for phrase in re.finditer(pattern, sentence)]:        \n",
    "        chunk, idnt, dst = make_chunk(phrase, filter_morphs(morphs))\n",
    "        dst_src_dict[dst].append(int(idnt))\n",
    "        chunk_list.append(chunk)\n",
    "    \n",
    "    return chunk_list\n",
    "\n",
    "with open(\"neko.txt.cabocha\", \"rt\") as neko:\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint([list_chunks(sentence) for sentence in list_sentences(neko.read())][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('あと', '聞くと'), ('で', '聞くと'), ('書生', '人間中で'), ('という', '人間中で'), ('一番', '獰悪な'), ('しかも', '種族であったそうだ。'), ('聞く', '種族であったそうだ。'), ('と', '種族であったそうだ。'), ('それ', '種族であったそうだ。'), ('は', '種族であったそうだ。'), ('人間', '種族であったそうだ。'), ('中', '種族であったそうだ。'), ('で', '種族であったそうだ。'), ('獰悪', '種族であったそうだ。'), ('な', '種族であったそうだ。')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"neko.txt.cabocha\", \"rt\") as neko:\n",
    "    sentences = [list_chunks(sentence) for sentence in list_sentences(neko.read())][8:9]\n",
    "    print([(srcmorph.surface, \"\".join(map(lambda x: x.surface, chunk.morphs)))\n",
    "           for sentence in sentences\n",
    "           for chunk in sentence\n",
    "           for srcidx in chunk.srcs\n",
    "           for srcmorph in sentence[srcidx].morphs\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
